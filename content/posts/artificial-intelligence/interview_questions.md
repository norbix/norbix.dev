# Topics

- imbalanced Classes
- overfitting
- underfitting
- neural networks
- interview questions

## âš–ï¸ Imbalanced Classes
What it is

- When one class dominates the dataset (e.g., 95% class A, 5% class B).

- Accuracy becomes misleading â€” predicting only the majority class gives high accuracy but useless results.

Why it matters

- Common in real-world: fraud detection, disease diagnosis, anomaly detection.

How to handle it

- Data-level approaches:

    - Oversampling minority (e.g., SMOTE).

    - Undersampling majority.

- Algorithm-level approaches:

    - Use class weights (heavier penalty on minority misclassification).

    - Cost-sensitive learning.

- Evaluation metrics:

    - Prefer Precision, Recall, F1, ROC-AUC, PR-AUC over Accuracy.

ğŸ‘‰ Interview line: â€œWith imbalanced data, I adjust sampling or class weights and focus on metrics like F1 or ROC-AUC, not just accuracy.â€

## ğŸ­ Overfitting
What it is

- Model memorizes training data, including noise.

- Training accuracy â‰« Validation accuracy.

Causes

- Too complex model, too few samples, training too long.

Fixes

- Regularization (L1, L2, dropout).

- Early stopping.

- Simplify the model.

- Data augmentation (esp. in CV).

ğŸ‘‰ Interview line: â€œOverfitting is high variance â€” I reduce it with regularization, dropout, early stopping, or more data.â€

## ğŸŒ± Underfitting

What it is

- Model is too simple to capture patterns.

- Training accuracy is low, validation accuracy also low.

Causes

- Oversimplified model.

- Too much regularization.

- Too little training.

Fixes

- Increase model complexity (deeper network, more features).

- Reduce regularization.

- Train longer / better learning rate.

ğŸ‘‰ Interview line: â€œUnderfitting is high bias â€” I fix it with a more complex model, more features, or longer training.â€

## ğŸ§  Neural Networks (NNs)

What they are

- Inspired by the brain.

- Composed of layers of neurons (Input â†’ Hidden â†’ Output).

- Each neuron computes: weighted sum + bias â†’ activation function.

How they learn

- Forward pass â†’ compute output.

- Loss function â†’ measure error.

- Backpropagation â†’ compute gradients.

- Gradient descent â†’ update weights.

Key architectures

- Feedforward (MLP) â€“ classic, tabular data.

- CNNs â€“ vision tasks, extract spatial features.

- RNNs / LSTMs â€“ sequences, time-series, speech.

- Transformers â€“ modern LLMs, attention mechanism.

ğŸ‘‰ Interview line: â€œNeural networks stack layers of nonlinear transformations. They learn via backpropagation and gradient descent. CNNs for images, RNNs for sequences, Transformers for language.â€

## ğŸ”‘ Likely Interview Questions

- â€œIf you have a dataset with 99% negative and 1% positive, how do you evaluate your model?â€

- â€œWhatâ€™s the difference between overfitting and underfitting? How would you detect each?â€

- â€œHow does backpropagation work in a neural network?â€

- â€œWhy do we need activation functions in neural networks?â€

- â€œHow would you prevent overfitting in a deep learning model?â€

### â€œIf you have a dataset with 99% negative and 1% positive, how do you evaluate your model?â€

Correct Interview Approach

1. Point out why accuracy is misleading

â€œIf I use accuracy, the model could predict all negatives and still get 99%, but it would miss all positives â€” so itâ€™s useless.â€

2. Propose better metrics

- Precision = TP / (TP+FP) â†’ how many predicted positives are correct.

- Recall (Sensitivity) = TP / (TP+FN) â†’ how many actual positives the model catches.

- F1-score = harmonic mean of Precision & Recall.

- ROC-AUC = ability to distinguish classes.

- PR-AUC = especially important for highly skewed data.

3. Mention strategies to balance evaluation

- Use confusion matrix.

- Adjust decision threshold.

- Use class weights or sampling techniques.


Model Answer (you can say in the interview):

â€œIn a dataset with 99% negatives and 1% positives, accuracy is misleading because predicting only negatives gives 99% accuracy but 0% recall. I would evaluate using metrics like Precision, Recall, F1-score, and ROC/PR-AUC. For example, in fraud detection, Recall is critical since missing a fraud is more costly than a few false positives.â€

### â€œWhatâ€™s the difference between overfitting and underfitting? How would you detect each?â€

ğŸ” Difference

- Overfitting (high variance)

    - Model learns the training data too well, including noise.

    - Performs great on training data, poorly on unseen data.

    - Cause: model too complex, too many parameters, too little data.

- Underfitting (high bias)

    - Model is too simple to capture patterns.

    - Performs poorly on both training and unseen data.

    - Cause: model too shallow/simple, too strong regularization, not enough training.

ğŸ§ª How to Detect

- Overfitting:

    - Training accuracy â‰« Validation/Test accuracy.

    - Training loss keeps dropping, validation loss starts rising.

- Underfitting:

    - Both training and validation accuracy are low.

    - Loss is high and does not improve much during training.

ğŸ¤ Interview-style Answer (30s)

â€œOverfitting happens when a model memorizes training data, so it performs well on train but poorly on test. Iâ€™d detect it if training accuracy is high but validation accuracy drops, or validation loss rises while training loss falls. Underfitting is the opposite â€” the model is too simple, performs badly on both train and test. Iâ€™d detect it if accuracy is low across the board. To fix overfitting, Iâ€™d use regularization, dropout, or early stopping. To fix underfitting, Iâ€™d increase model complexity, add features, or train longer.â€


### â€œHow does backpropagation work in a neural network?â€

ğŸ” Backpropagation in a Nutshell

Goal: Adjust weights so the networkâ€™s predictions get closer to the correct outputs.

Step-by-step

Forward pass

Input flows through the network (Input â†’ Hidden Layers â†’ Output).

Each neuron computes: weighted sum + bias â†’ activation.

Output is produced.

Loss calculation

Compare prediction with the true label using a loss function (e.g., cross-entropy, MSE).

Backward pass (backpropagation)

Compute how much each weight contributed to the error.

Use the chain rule of calculus to propagate gradients backward layer by layer.

Each neuron gets a gradient telling it how to adjust.

Weight update (optimization)

Optimizer (SGD, Adam, RMSProp, etc.) updates weights:

    weight = weight - learning_rate * gradient

= gradient of loss wrt weight.

Repeat

Do this for many epochs until the network converges.

ğŸ¤ Interview-style Answer (30s)

â€œBackpropagation is the process of updating neural network weights using the chain rule of calculus. First, the network makes a forward pass and computes a loss. Then, gradients of the loss are propagated backward through the layers, showing how much each weight contributed to the error. Finally, an optimizer like SGD or Adam updates the weights in the direction that reduces the loss. This cycle repeats until the model converges.â€

### â€œWhy do we need activation functions in neural networks?â€

1. Introduce Non-linearity

    - Without activation functions, a neural network is just a stack of linear transformations.

    - Multiple linear layers collapse into one â†’ equivalent to linear regression.

    - With nonlinear activations (ReLU, sigmoid, tanh), the network can approximate nonlinear decision boundaries.

1. Allow Complex Representations

    - Nonlinear activations let the network capture patterns like curves, images, language, etc.

    - They allow hierarchical feature extraction: edges â†’ shapes â†’ objects â†’ semantics.

1. Enable Universal Approximation

    - The Universal Approximation Theorem: a neural network with at least one hidden layer and nonlinear activation can approximate any continuous function.

#### ğŸ› ï¸ Common Activation Functions

- Sigmoid (Ïƒ) â€“ squashes values to [0, 1], used in binary classification.

- Tanh â€“ squashes to [-1, 1], zero-centered.

- ReLU â€“ Rectified Linear Unit, most popular in deep learning (simple & efficient).

- Softmax â€“ converts outputs into probabilities for multi-class classification.

#### ğŸ¤ Interview-style Answer (30s)

â€œWe need activation functions to introduce nonlinearity. Without them, a neural network is just a linear model, no matter how many layers we stack. Activation functions like ReLU, sigmoid, and tanh allow the network to learn complex, nonlinear patterns and approximate any function. Thatâ€™s what makes deep learning powerful.â€

### â€œHow would you prevent overfitting in a deep learning model?â€

1. Regularization

- L1 (Lasso) â†’ encourages sparsity.

- L2 (Ridge / weight decay) â†’ keeps weights small.

- Prevents the model from fitting noise.

2. Dropout

- Randomly â€œturns offâ€ neurons during training.

- Forces the network to not rely too much on specific connections.

- Typical rates: 0.2â€“0.5.

3. Early Stopping

- Monitor validation loss.

- Stop training when validation performance starts degrading.

4. Data Augmentation

- Especially for CV and NLP.

- Images: rotation, flipping, cropping, color jitter.

- Text: synonym replacement, back-translation.

- Makes the model generalize better.

5. Simpler Models

- Reduce network depth/width.

- Over-parameterized models tend to memorize.

6. More Data

- The most powerful fix.

- Collect more samples or generate synthetic ones (SMOTE, GANs).

7. Batch Normalization & Regular Training Tricks

- Normalizes activations â†’ smoother training.

- Use proper learning rate schedules.

#### ğŸ¤ Interview-style Answer (30s)

â€œOverfitting means the model memorizes training data instead of generalizing. Iâ€™d detect it when training accuracy is high but validation accuracy drops. To prevent it, Iâ€™d apply regularization (L1/L2), dropout, early stopping, and data augmentation. If possible, Iâ€™d also gather more data or simplify the model. In practice, I usually monitor validation curves and apply these techniques iteratively.â€
